{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Machine Learning Workflow Template\n",
        "\n",
        "**Purpose**: End-to-end machine learning pipeline template\n",
        "\n",
        "**Author**: [Your Name]\n",
        "\n",
        "**Date**: [Date]\n",
        "\n",
        "**Project**: [Project Name]\n",
        "\n",
        "**Model Type**: [Classification/Regression/Clustering]\n",
        "\n",
        "---\n",
        "\n",
        "## Template Instructions\n",
        "\n",
        "This template provides a structured approach to machine learning workflows:\n",
        "\n",
        "1. **Environment Setup & Data Loading**\n",
        "2. **Exploratory Data Analysis**\n",
        "3. **Data Preprocessing**\n",
        "4. **Feature Engineering**\n",
        "5. **Model Selection & Training**\n",
        "6. **Model Evaluation**\n",
        "7. **Hyperparameter Tuning**\n",
        "8. **Model Deployment Preparation**\n",
        "9. **Documentation & Reporting**\n",
        "\n",
        "**Remember to**:\n",
        "- Set up MLflow experiment tracking\n",
        "- Version control your data and models\n",
        "- Document all assumptions and decisions\n",
        "- Follow reproducible ML practices\n",
        "- Validate results thoroughly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Environment Setup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "import joblib\n",
        "import pickle\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Machine Learning Libraries\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# MLflow for experiment tracking\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "# Configuration\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.max_columns', None)\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "# MLflow setup\n",
        "EXPERIMENT_NAME = \"ml-workflow-template\"\n",
        "mlflow.set_experiment(EXPERIMENT_NAME)\n",
        "\n",
        "# Create directories for artifacts\n",
        "Path(\"models\").mkdir(exist_ok=True)\n",
        "Path(\"data\").mkdir(exist_ok=True)\n",
        "Path(\"reports\").mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"üöÄ ML Environment setup complete\")\n",
        "print(f\"üî¨ MLflow experiment: {EXPERIMENT_NAME}\")\n",
        "print(f\"üé≤ Random seed: {RANDOM_SEED}\")\n",
        "print(f\"üìÖ Analysis date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 1. Data Loading & Initial Setup\n",
        "\n",
        "Load your dataset and perform initial data exploration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model Training with MLflow Tracking\n",
        "with mlflow.start_run(run_name=f\"ml-template-{datetime.now().strftime('%Y%m%d_%H%M%S')}\"):\n",
        "    \n",
        "    # TODO: Replace with your data loading code\n",
        "    # df = pd.read_csv('your_dataset.csv')\n",
        "    \n",
        "    # Example: Load sample data\n",
        "    from sklearn.datasets import load_iris\n",
        "    iris = load_iris()\n",
        "    X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "    y = pd.Series(iris.target)\n",
        "    \n",
        "    # Log dataset info\n",
        "    mlflow.log_param(\"dataset_shape\", X.shape)\n",
        "    mlflow.log_param(\"n_features\", X.shape[1])\n",
        "    mlflow.log_param(\"n_samples\", X.shape[0])\n",
        "    mlflow.log_param(\"target_classes\", len(np.unique(y)))\n",
        "    \n",
        "    # Train-test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y\n",
        "    )\n",
        "    \n",
        "    # Feature scaling\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    \n",
        "    # Model training\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED)\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    \n",
        "    # Predictions\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_pred_proba = model.predict_proba(X_test_scaled)\n",
        "    \n",
        "    # Evaluate model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    \n",
        "    # Log metrics\n",
        "    mlflow.log_metric(\"accuracy\", accuracy)\n",
        "    mlflow.log_metric(\"train_score\", model.score(X_train_scaled, y_train))\n",
        "    mlflow.log_metric(\"test_score\", model.score(X_test_scaled, y_test))\n",
        "    \n",
        "    # Log model\n",
        "    mlflow.sklearn.log_model(model, \"model\")\n",
        "    \n",
        "    # Save preprocessing pipeline\n",
        "    joblib.dump(scaler, \"models/scaler.pkl\")\n",
        "    mlflow.log_artifact(\"models/scaler.pkl\")\n",
        "    \n",
        "    print(f\"‚úÖ Model trained successfully\")\n",
        "    print(f\"üìä Test Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"üìà Training Score: {model.score(X_train_scaled, y_train):.4f}\")\n",
        "    print(f\"üìâ Test Score: {model.score(X_test_scaled, y_test):.4f}\")\n",
        "    \n",
        "    # Feature importance\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'feature': X.columns,\n",
        "        'importance': model.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "    \n",
        "    print(f\"\\nüîç Feature Importance:\")\n",
        "    print(feature_importance)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
