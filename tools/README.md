# Development Tools & Utilities

## Overview

The `tools` directory contains development utilities, helper tools, and specialized scripts that support the Modern Data Stack Showcase development workflow. These tools enhance developer productivity, ensure code quality, and provide utilities for testing, debugging, and platform management.

## üõ†Ô∏è **Tool Categories**

### **Development Utilities**
- **Code Generators**: Templates and scaffolding for new components
- **Data Generators**: Synthetic data creation and management tools
- **Configuration Managers**: Environment and configuration management utilities
- **Testing Helpers**: Test data generation and validation utilities

### **Quality Assurance Tools**
- **Code Formatters**: Automated code formatting and style enforcement
- **Linters**: Code quality analysis and issue detection
- **Security Scanners**: Vulnerability detection and security validation
- **Performance Analyzers**: Performance profiling and optimization tools

### **Platform Management**
- **Database Tools**: Database management and migration utilities
- **Infrastructure Tools**: Infrastructure management and automation helpers
- **Monitoring Tools**: System monitoring and alerting utilities
- **Deployment Tools**: Deployment validation and rollback utilities

## üìÅ **Tool Structure**

```
tools/
‚îú‚îÄ‚îÄ README.md                    # This overview document
‚îú‚îÄ‚îÄ code-generators/             # Code scaffolding and generation
‚îÇ   ‚îú‚îÄ‚îÄ generate_ml_notebook.py # ML notebook template generator
‚îÇ   ‚îú‚îÄ‚îÄ create_dbt_model.py     # dbt model scaffolding
‚îÇ   ‚îú‚îÄ‚îÄ scaffold_api.py         # API endpoint generator
‚îÇ   ‚îî‚îÄ‚îÄ generate_tests.py       # Test template generator
‚îú‚îÄ‚îÄ data-tools/                  # Data management utilities
‚îÇ   ‚îú‚îÄ‚îÄ synthetic_data_gen.py   # Advanced synthetic data generator
‚îÇ   ‚îú‚îÄ‚îÄ data_validator.py       # Data quality validation
‚îÇ   ‚îú‚îÄ‚îÄ schema_comparator.py    # Schema comparison utility
‚îÇ   ‚îî‚îÄ‚îÄ data_profiler.py        # Data profiling and analysis
‚îú‚îÄ‚îÄ quality-tools/               # Code quality and analysis
‚îÇ   ‚îú‚îÄ‚îÄ code_analyzer.py        # Comprehensive code analysis
‚îÇ   ‚îú‚îÄ‚îÄ security_scanner.py     # Security vulnerability scanner
‚îÇ   ‚îú‚îÄ‚îÄ performance_profiler.py # Performance analysis
‚îÇ   ‚îî‚îÄ‚îÄ dependency_checker.py   # Dependency analysis and updates
‚îú‚îÄ‚îÄ infrastructure-tools/        # Infrastructure management
‚îÇ   ‚îú‚îÄ‚îÄ cluster_manager.py      # Kubernetes cluster management
‚îÇ   ‚îú‚îÄ‚îÄ resource_monitor.py     # Resource usage monitoring
‚îÇ   ‚îú‚îÄ‚îÄ config_validator.py     # Configuration validation
‚îÇ   ‚îî‚îÄ‚îÄ backup_manager.py       # Backup and recovery tools
‚îî‚îÄ‚îÄ dev-helpers/                 # Development workflow helpers
    ‚îú‚îÄ‚îÄ environment_setup.py    # Development environment manager
    ‚îú‚îÄ‚îÄ log_analyzer.py         # Log analysis and debugging
    ‚îú‚îÄ‚îÄ api_tester.py           # API testing and validation
    ‚îî‚îÄ‚îÄ notebook_runner.py      # Automated notebook execution
```

## üéØ **Key Tools**

### **Code Generators** (`code-generators/`)

#### **ML Notebook Generator**
```python
# Generate ML notebook from template
python tools/code-generators/generate_ml_notebook.py \
    --name "customer-segmentation" \
    --type "classification" \
    --data-source "customer_data" \
    --output notebooks/ml-workflows/
```

**Features:**
- **Template-based Generation**: Create notebooks from predefined templates
- **Customizable Workflows**: Support for different ML workflow types
- **Best Practices**: Include enterprise patterns and documentation standards
- **Integration Ready**: Pre-configured for MLflow and monitoring

#### **dbt Model Scaffolding**
```python
# Create new dbt model with proper structure
python tools/code-generators/create_dbt_model.py \
    --model-name "customer_analysis" \
    --layer "analytics" \
    --connector "retail" \
    --depends-on "staging_customers,staging_orders"
```

**Features:**
- **Layer-Aware**: Automatically place models in correct architectural layer
- **Dependency Management**: Set up proper model dependencies
- **Documentation**: Generate documentation templates
- **Testing**: Include standard test templates

### **Data Tools** (`data-tools/`)

#### **Advanced Synthetic Data Generator**
```python
# Generate realistic synthetic data
python tools/data-tools/synthetic_data_gen.py \
    --schema config/retail_schema.yaml \
    --output sample-data/retail/ \
    --records 100000 \
    --format parquet
```

**Features:**
- **Schema-Driven**: Generate data based on schema definitions
- **Realistic Patterns**: Create data with realistic distributions and relationships
- **Privacy Compliant**: Ensure no real data is used in generated datasets
- **Multi-Format**: Support for CSV, Parquet, JSON output formats

#### **Data Quality Validator**
```python
# Validate data quality across datasets
python tools/data-tools/data_validator.py \
    --input data/staging/ \
    --rules config/quality_rules.yaml \
    --output reports/data_quality_report.html
```

**Features:**
- **Rule-Based Validation**: Define custom data quality rules
- **Comprehensive Reporting**: Generate detailed quality reports
- **Integration**: Works with Great Expectations and dbt tests
- **Automated Alerts**: Send notifications for quality issues

### **Quality Tools** (`quality-tools/`)

#### **Code Analyzer**
```python
# Comprehensive code analysis
python tools/quality-tools/code_analyzer.py \
    --path src/ \
    --output reports/code_analysis.html \
    --include-metrics complexity,maintainability,security
```

**Features:**
- **Multi-Dimensional Analysis**: Code complexity, maintainability, security
- **Trend Tracking**: Track code quality over time
- **Integration**: Works with CI/CD pipelines
- **Actionable Insights**: Provide specific improvement recommendations

#### **Security Scanner**
```python
# Security vulnerability scanning
python tools/quality-tools/security_scanner.py \
    --scan-type full \
    --output reports/security_scan.json \
    --include dependencies,secrets,vulnerabilities
```

**Features:**
- **Comprehensive Scanning**: Dependencies, secrets, code vulnerabilities
- **Integration**: Works with Bandit, Safety, and other security tools
- **Reporting**: Generate detailed security reports
- **CI/CD Integration**: Automated security validation

### **Infrastructure Tools** (`infrastructure-tools/`)

#### **Cluster Manager**
```python
# Kubernetes cluster management
python tools/infrastructure-tools/cluster_manager.py \
    --action deploy \
    --environment staging \
    --validate-health \
    --wait-for-ready
```

**Features:**
- **Environment Management**: Manage multiple Kubernetes environments
- **Health Validation**: Automatic health checks after deployment
- **Resource Monitoring**: Track resource usage and performance
- **Rollback Capability**: Automated rollback on deployment issues

#### **Resource Monitor**
```python
# Monitor system resources
python tools/infrastructure-tools/resource_monitor.py \
    --metrics cpu,memory,disk,network \
    --interval 30 \
    --alert-thresholds config/alert_thresholds.yaml
```

**Features:**
- **Real-Time Monitoring**: Continuous resource monitoring
- **Alerting**: Configurable alert thresholds and notifications
- **Historical Data**: Store and analyze historical resource usage
- **Dashboard Integration**: Export metrics to Grafana and other tools

## üöÄ **Usage Patterns**

### **Development Workflow**
```bash
# 1. Set up development environment
python tools/dev-helpers/environment_setup.py --profile development

# 2. Generate new ML notebook
python tools/code-generators/generate_ml_notebook.py \
    --name "fraud-detection" --type "classification"

# 3. Generate synthetic data for testing
python tools/data-tools/synthetic_data_gen.py \
    --schema config/fraud_schema.yaml --records 10000

# 4. Run code quality checks
python tools/quality-tools/code_analyzer.py --path notebooks/

# 5. Validate infrastructure
python tools/infrastructure-tools/config_validator.py \
    --config infrastructure/terraform/
```

### **CI/CD Integration**
```yaml
# Example CI/CD integration
name: Quality Gates
on: [push, pull_request]

jobs:
  quality-checks:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    
    - name: Code Analysis
      run: |
        python tools/quality-tools/code_analyzer.py \
          --path src/ --output reports/code_analysis.json
    
    - name: Security Scan
      run: |
        python tools/quality-tools/security_scanner.py \
          --output reports/security_scan.json
    
    - name: Data Quality Validation
      run: |
        python tools/data-tools/data_validator.py \
          --input sample-data/ --rules config/quality_rules.yaml
```

## üîß **Tool Configuration**

### **Configuration Management**
```yaml
# tools/config/default.yaml
code_generators:
  templates_path: "tools/templates/"
  output_path: "generated/"
  include_documentation: true
  include_tests: true

data_tools:
  default_records: 1000
  default_format: "parquet"
  privacy_mode: true
  seed: 42

quality_tools:
  code_analysis:
    complexity_threshold: 10
    maintainability_threshold: 75
  security_scan:
    severity_threshold: "medium"
    fail_on_high: true

infrastructure_tools:
  kubernetes:
    default_namespace: "default"
    timeout: 300
  monitoring:
    interval: 30
    retention_days: 30
```

### **Environment Variables**
```bash
# Tool-specific environment variables
export TOOLS_CONFIG_PATH=tools/config/
export TOOLS_OUTPUT_PATH=reports/
export TOOLS_CACHE_PATH=.tools-cache/
export TOOLS_LOG_LEVEL=INFO
```

## üìä **Tool Outputs & Reporting**

### **Report Generation**
Tools generate comprehensive reports in multiple formats:

- **HTML Reports**: Interactive reports with visualizations
- **JSON Reports**: Machine-readable reports for CI/CD integration
- **PDF Reports**: Formal reports for documentation and compliance
- **Dashboard Integration**: Export metrics to monitoring dashboards

### **Example Report Structure**
```json
{
  "tool": "code_analyzer",
  "timestamp": "2024-01-15T10:30:00Z",
  "summary": {
    "total_files": 150,
    "total_lines": 25000,
    "complexity_score": 7.2,
    "maintainability_score": 82
  },
  "details": {
    "high_complexity_files": [...],
    "code_smells": [...],
    "security_issues": [...]
  },
  "recommendations": [...]
}
```

## üîç **Tool Development**

### **Creating New Tools**
```python
# Template for new tool development
#!/usr/bin/env python3
"""
Tool Name: Custom Analysis Tool
Description: Brief description of tool functionality
Author: Development Team
"""

import argparse
import logging
from pathlib import Path
from typing import Dict, List, Any

class CustomTool:
    """Custom tool implementation."""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = logging.getLogger(__name__)
    
    def run(self, inputs: List[str]) -> Dict[str, Any]:
        """Execute the tool with given inputs."""
        # Tool implementation
        return {"status": "success", "results": {}}

def main():
    """Main entry point for the tool."""
    parser = argparse.ArgumentParser(description="Custom Analysis Tool")
    parser.add_argument("--input", required=True, help="Input path")
    parser.add_argument("--output", help="Output path")
    parser.add_argument("--config", help="Configuration file")
    
    args = parser.parse_args()
    
    # Tool execution
    tool = CustomTool(config={})
    results = tool.run([args.input])
    
    print(f"Tool completed: {results['status']}")

if __name__ == "__main__":
    main()
```

### **Tool Testing**
```python
# Test template for tools
import pytest
from tools.data_tools.synthetic_data_gen import SyntheticDataGenerator

class TestSyntheticDataGenerator:
    """Test suite for synthetic data generator."""
    
    def test_basic_generation(self):
        """Test basic data generation functionality."""
        generator = SyntheticDataGenerator()
        result = generator.generate(schema="simple", records=100)
        
        assert len(result) == 100
        assert result.columns.tolist() == ["id", "name", "value"]
    
    def test_schema_validation(self):
        """Test schema validation."""
        generator = SyntheticDataGenerator()
        
        with pytest.raises(ValueError):
            generator.generate(schema="invalid", records=100)
```

## üìö **Documentation & Support**

### **Tool Documentation**
Each tool includes comprehensive documentation:

- **Purpose**: Clear description of tool functionality
- **Usage**: Command-line interface and parameter documentation
- **Examples**: Practical usage examples and scenarios
- **Configuration**: Configuration options and customization
- **Integration**: How to integrate with other tools and workflows

### **Getting Help**
```bash
# Get help for any tool
python tools/[category]/[tool_name].py --help

# View tool documentation
python tools/[category]/[tool_name].py --docs

# List available tools
python tools/list_tools.py
```

### **Contributing New Tools**
1. **Follow Standards**: Use the tool template and coding standards
2. **Include Tests**: Comprehensive test coverage for all functionality
3. **Documentation**: Complete documentation and usage examples
4. **Integration**: Ensure compatibility with existing workflow
5. **Review Process**: Submit for code review and validation

## üéØ **Best Practices**

### **Tool Development Guidelines**
- **Single Responsibility**: Each tool should have a clear, focused purpose
- **Configurable**: Support configuration files and command-line options
- **Testable**: Include comprehensive unit and integration tests
- **Documented**: Provide clear documentation and usage examples
- **Integrated**: Work seamlessly with existing development workflow

### **Usage Guidelines**
- **Version Control**: Keep tool configurations in version control
- **Automation**: Integrate tools into CI/CD pipelines where appropriate
- **Monitoring**: Monitor tool performance and resource usage
- **Updates**: Keep tools updated with latest features and security patches

---

**üõ†Ô∏è These development tools enhance productivity and ensure quality across the Modern Data Stack platform development lifecycle.** 